"""
Regression model-level training, prediction and complexity
measurement routines. 
This module does not manage experiment orchestration, which is
handled separately by the evaluator.

This module implements:

- model-specific training/evaluation wrappers
- structural complexity measures for interpretable models
- a unified metric computation interface

Functions here return dictionaries of evaluation metrics and (when applicable)
structural complexity values to allow uniform comparison across models in
the paper.
"""

import pandas as pd
import math
from sklearn.metrics import (
    mean_absolute_error,
    r2_score,
    mean_squared_error,
)
from numpy import log2

from ..config.config import *
from .utils_model_io import save_model, load_model


# ============================================================================
#                            METRIC COMPUTATION
# ============================================================================

def regression_metrics(y_true, y_pred, model=None, model_file_name=None):
    """
    Compute regression metrics and optionally save the trained model.

    Parameters
    ----------
    y_true : array-like
        Ground-truth numerical labels.
    y_pred : array-like
        Predictions generated by the model.
    model : estimator, optional
        Model instance to save.
    model_file_name : str, optional
        Name used when saving the model.

    Returns
    -------
    dict
        Dictionary containing MAE, MSE, R² and structural complexity (if available).
    """
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    results = {"MAE": mae, "MSE": mse, "R2": r2, "complexity": 0}

    # Optionally save the model to disk
    if model:
        save_model(model, model_file_name)

    logger.info(results)
    return results


# ============================================================================
#                          SYMBOLIC REGRESSION (PySR)
# ============================================================================

def symbolic_regression_performances(
    hyperparams, X_train, X_test, y_train, y_test,
    save=False, fit=True, load_params=False):
    """Train or load a PySR symbolic regressor and compute evaluation metrics."""
    from pysr import PySRRegressor

    if fit:
        model = PySRRegressor(**hyperparams)
        model.fit(X_train, y_train)
    else:
        model = load_model("symbolic_regression", load_params)

        # PySR needs consistent column names when loading a model
        feat_names = getattr(model, "feature_names_in_", None)
        if feat_names is not None:
            if not hasattr(X_test, "columns"):
                X_test = pd.DataFrame(X_test, columns=[f"x{i}" for i in range(X_test.shape[1])])

            missing = [c for c in feat_names if c not in X_test.columns]
            if missing:
                raise ValueError(f"Missing required columns for PySR model: {missing}")

            X_test = X_test[list(feat_names)]
        else:
            X_test = np.asarray(X_test)

    y_pred = model.predict(X_test)

    results = regression_metrics(y_test, y_pred, model, save) if save else regression_metrics(y_test, y_pred)

    results["complexity"] = model.get_best()["complexity"]
    return results


# ============================================================================
#                        LINEAR REGRESSION
# ============================================================================

def linear_regression_performances(
    hyperparams, X_train, X_test, y_train, y_test,
    save=False, fit=True, load_params=False):
    """Train or load a Linear Regression model and compute performance metrics."""
    from sklearn.linear_model import LinearRegression

    if fit:
        model = LinearRegression(**hyperparams)
        model.fit(X_train, y_train)
    else:
        model = load_model("linear_regression", load_params)

    y_pred = model.predict(X_test)

    return regression_metrics(y_test, y_pred, model, save) if save else regression_metrics(y_test, y_pred)


# ============================================================================
#                     DECISION TREE REGRESSOR
# ============================================================================

def decision_tree_regressor_performances(
    hyperparams, X_train, X_test, y_train, y_test,
    save=False, fit=True, load_params=False):
    """Train or load a Decision Tree Regressor and compute performance metrics."""
    from sklearn.tree import DecisionTreeRegressor

    if fit:
        hyperparams["max_depth"] = math.ceil(log2(X_train.shape[1])) + 2
        model = DecisionTreeRegressor(**hyperparams)
        model.fit(X_train, y_train)
    else:
        model = load_model("decision_tree_regressor", load_params)

    y_pred = model.predict(X_test)

    results = regression_metrics(y_test, y_pred, model, save) if save else regression_metrics(y_test, y_pred)

    results["complexity"] = model.tree_.node_count
    return results


# ============================================================================
#                          KNN REGRESSOR
# ============================================================================

def knn_performances(
    hyperparams, X_train, X_test, y_train, y_test,
    save=False, fit=True, load_params=False):
    """Train or load a KNN Regressor, then compute regression metrics."""
    from sklearn.neighbors import KNeighborsRegressor

    if fit:
        model = KNeighborsRegressor(**hyperparams)
        model.fit(X_train, y_train)
    else:
        model = load_model("knn", load_params)

    y_pred = model.predict(X_test)

    return regression_metrics(y_test, y_pred, model, save) if save else regression_metrics(y_test, y_pred)


# ============================================================================
#                 EXPLAINABLE BOOSTING MACHINE (EBM)
# ============================================================================

def ebm_structural_complexity(model):
    """
    Structural complexity of EBM:
    total number of learned step bins across all univariate and interaction terms.
    """
    return sum(len(score) for score in model.term_scores_)


def ebm_performances(
    hyperparams, X_train, X_test, y_train, y_test,
    save=False, fit=True, load_params=False):
    """Train or load an EBM regressor and compute metrics including complexity."""
    from interpret.glassbox import ExplainableBoostingRegressor

    if fit:
        model = ExplainableBoostingRegressor(**hyperparams)
        model.fit(X_train, y_train)
    else:
        model = load_model("ebm", load_params)

    y_pred = model.predict(X_test)

    results = regression_metrics(y_test, y_pred, model, save) if save else regression_metrics(y_test, y_pred)

    results["complexity"] = ebm_structural_complexity(model)
    return results


# ============================================================================
#                           LASSO
# ============================================================================

def lasso_performances(
    hyperparams, X_train, X_test, y_train, y_test,
    save=False, fit=True, load_params=False):
    """Train or load a Lasso regressor and compute performance metrics."""
    from sklearn.linear_model import Lasso

    if fit:
        model = Lasso(**hyperparams)
        model.fit(X_train, y_train)
    else:
        model = load_model("lasso", load_params)

    y_pred = model.predict(X_test)

    return regression_metrics(y_test, y_pred, model, save) if save else regression_metrics(y_test, y_pred)


# ============================================================================
#                          GLM (TWEEDIE)
# ============================================================================

def glm_performances(
    hyperparams, X_train, X_test, y_train, y_test,
    save=False, fit=True, load_params=False):
    """Train or load a Tweedie GLM regressor."""
    from sklearn.linear_model import TweedieRegressor

    if fit:
        model = TweedieRegressor(**hyperparams)
        model.fit(X_train, y_train)
    else:
        model = load_model("glm", load_params)

    y_pred = model.predict(X_test)

    return regression_metrics(y_test, y_pred, model, save) if save else regression_metrics(y_test, y_pred)


# ============================================================================
#                        POLYNOMIAL LASSO
# ============================================================================

def poly_lasso_performances(
    hyperparams, X_train, X_test, y_train, y_test,
    save=False, fit=True, load_params=False):
    """
    Train or load a PolynomialFeatures → Lasso pipeline.

    Automatically switches between LassoLarsIC (for p < n) and LassoLarsCV
    (for p >= n) to avoid instability when dimensionality exceeds sample size.
    """
    import numpy as np
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.linear_model import LassoLarsIC, LassoLarsCV
    from sklearn.pipeline import Pipeline

    def _filtered_params(pipe, params):
        """Filter out hyperparameters incompatible with the constructed pipeline."""
        valid = set(pipe.get_params().keys())
        return {k: v for k, v in params.items() if k in valid}

    if fit:
        degree = hyperparams.get("poly__degree", 2)
        include_bias = hyperparams.get("poly__include_bias", False)

        probe = PolynomialFeatures(degree=degree, include_bias=include_bias)
        p = probe.fit_transform(X_train[:min(len(X_train), 100)]).shape[1]
        n = len(y_train)

        lasso_step = LassoLarsIC() if p < n else LassoLarsCV(cv=min(5, n))

        model = Pipeline([
            ("poly", PolynomialFeatures()),
            ("lasso", lasso_step)
        ])

        model.set_params(**_filtered_params(model, hyperparams))
        model.fit(X_train, y_train)
    else:
        model = load_model("poly_lasso", load_params)

    y_pred = model.predict(X_test)

    return regression_metrics(y_test, y_pred, model, save) if save else regression_metrics(y_test, y_pred)


# ============================================================================
#                              IGANN REGRESSOR
# ============================================================================

def igann_performances(
    hyperparams, X_train, X_test, y_train, y_test,
    save=False, fit=True, load_params=False):
    """
    Train an IGANN regressor and compute metrics.

    Note: Input matrices must be converted to pandas DataFrames for IGANN.
    """
    from igann import IGANNRegressor

    if not isinstance(X_train, pd.DataFrame):
        X_train = pd.DataFrame(X_train)
    if not isinstance(X_test, pd.DataFrame):
        X_test = pd.DataFrame(X_test)

    if fit:
        model = IGANNRegressor(**hyperparams)
        model.fit(X_train, y_train)
    else:
        model = load_model("igann", load_params)
    
    y_pred = model.predict(X_test)

    return regression_metrics(y_test, y_pred, model, save) if save else regression_metrics(y_test, y_pred)
